{
	"rnn_unit": [1024],
	"rnn_cell": "lstm",
	"encoder_rnn_type": "unidirectional",
	"attention_mechanism": null,
	"attention_size": null,
	"dense_layers": [4096],
	"dense_activation": "sigmoid",
	"optimizer": "adam",
	"learning_rate": 0.001,
	"dropout_keep_prob_dense": 0.8,
	"dropout_keep_prob_rnn_input": 0.8,
	"dropout_keep_prob_rnn_output": 0.8,
	"dropout_keep_prob_rnn_state": 0.8,
	"bucket_use_padding": true,
	"bucket_padding_input": [3, 5, 10, 15, 20],
	"bucket_padding_output": [1, 2, 3, 5, 10, 15, 21],
	"train_epochs": 3,
	"train_steps": 2500,
	"train_batch_size": 512,
	"log_per_step_percent": 10,
	"embedding_use_pretrained": false,
	"embedding_pretrained_path": "model/cc.en.300",
	"embedding_type": "fasttext",
	"embedding_size": 300,
	"embedding_negative_sample": 128,
	"vocab_limit": 0,
	"vocab_special_token": ["<start>", "<end>", "<pad>", "<unk>"],
	"ngram": 3,
	"reverse_input_sequence": true,
	"seq2seq_loss": true
}